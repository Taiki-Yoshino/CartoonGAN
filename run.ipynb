{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from generator import Generator\n",
    "import torch\n",
    "from discriminator import Discriminator\n",
    "import torchvision.utils as vutils\n",
    "from torch import optim\n",
    "import fiftyone.zoo as foz\n",
    "from torchvision import transforms, utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "import pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = 0.5\n",
    "batch_size = 32\n",
    "img_size = 128 #64\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from preprocess_dataset import  SelectiveEdgeSmoothing, FiftyOnePyTorchDataset, \\\n",
    "                        ShuffledDatasetSampler, visualize_batch\n",
    "\n",
    "generic_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "gaussian_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    SelectiveEdgeSmoothing( img_size = img_size, radius=5, alpha=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load FiftyOne dataset\n",
    "fiftyone_dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\", max_samples=776)\n",
    "fo_dataset = FiftyOnePyTorchDataset(fiftyone_dataset, transform=generic_transform)\n",
    "real_images_loader = DataLoader(fo_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load Cartoon dataset\n",
    "cartoon_path = '../../GhibliDataset' \n",
    "cartoon_dataset = ImageFolder(root=cartoon_path, transform=generic_transform)\n",
    "sampler = ShuffledDatasetSampler(cartoon_dataset, seed=42)\n",
    "cartoon_images_loader = DataLoader(cartoon_dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "# Load Cartoon Edge dataset\n",
    "cartoon_edge_dataset = ImageFolder(root=cartoon_path, transform=gaussian_transform)\n",
    "cartoon_edge_images_loader = DataLoader(cartoon_edge_dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "\n",
    "# Visualize images\n",
    "batch_img = next(iter(real_images_loader))\n",
    "visualize_batch(batch_img, \"Some COCO Dataset Images\")\n",
    "\n",
    "batch_img, _ = next(iter(cartoon_images_loader)) \n",
    "visualize_batch(batch_img, \"Some Cartoon Dataset Images\")\n",
    "\n",
    "batch_img, _ = next(iter(cartoon_edge_images_loader))\n",
    "visualize_batch(batch_img, \"Some Cartoon Edge Dataset Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 0.0002\n",
    "#pretrained_generator = pretrain.fit(real_images_loader,  epochs, lr, beta1, device = device)\n",
    "pretrained_generator = torch.load('pretrained_generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import ContentLoss\n",
    "\n",
    "epochs = 200 \n",
    "lr = 0.0001\n",
    "\n",
    "generator = Generator().to(device) #pretrained_generator\n",
    "discriminator = Discriminator().to(device)\n",
    "adversarial_loss = nn.BCELoss().to(device)\n",
    "co_loss = ContentLoss().to(device)\n",
    "bce_loss = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_images, (cartoon_images, _), (cartoon_edge_images, _)) in enumerate(zip(real_images_loader, cartoon_images_loader, cartoon_edge_images_loader)):\n",
    "        \n",
    "        real_images = real_images.to(device)\n",
    "        cartoon_images = cartoon_images.to(device)\n",
    "        cartoon_edge_images = cartoon_edge_images.to(device)\n",
    "        batch_size = cartoon_images.size(0)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        #D\n",
    "        discriminator.zero_grad()\n",
    "        generated_images = generator(real_images)\n",
    "        cartoon_pred = discriminator(cartoon_images)\n",
    "        cartoon_edge_pred = discriminator(cartoon_edge_images)\n",
    "        generated_pred = discriminator(generated_images.detach())\n",
    "        \n",
    "        \n",
    "        loss_d = adversarial_loss(cartoon_pred, real_labels) + \\\n",
    "                adversarial_loss(generated_pred, fake_labels) + \\\n",
    "                adversarial_loss(cartoon_edge_pred, fake_labels)\n",
    "        loss_d.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        \n",
    "        #G\n",
    "        generator.zero_grad()\n",
    "        generated_pred = discriminator(generated_images)\n",
    "        loss_g = bce_loss(generated_pred, real_labels) + co_loss(generated_images, real_images)\n",
    "        loss_g.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        if i % 1 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}] Batch {i}/{len(cartoon_images_loader)}\")\n",
    "\n",
    "    if epoch % 1 == 0: \n",
    "        print(f\"Epoch [{epoch}/{epochs}] Batch [{i}/{len(real_images_loader)}]\")\n",
    "        fake_img_grid = vutils.make_grid(generated_images.detach().cpu(), padding=2, normalize=True)\n",
    "        real_img_grid = vutils.make_grid(real_images.detach().cpu(), padding=2, normalize=True)\n",
    "        \n",
    "\n",
    "        plt.figure(figsize=(16,30))\n",
    "        plt.axis(False)\n",
    "        plt.title(\"Original images\")\n",
    "        plt.imshow(real_img_grid.permute(1, 2, 0).squeeze())\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(16,30))\n",
    "        plt.axis(False)\n",
    "        plt.title(\"CartoonGAN images\")\n",
    "        plt.imshow(fake_img_grid.permute(1, 2, 0).squeeze())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = Generator().to(device)\n",
    "# discriminator = Discriminator().to(device)\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "# real_label = 1.\n",
    "# fake_label = 0.\n",
    "\n",
    "# optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(epochs):\n",
    "#     for i, (images, _) in enumerate(cartoon_images_loader):\n",
    "\n",
    "#         real_images = images.to(device)\n",
    "#         current_batch_size = real_images.size(0)\n",
    "#         real_labels = torch.full((current_batch_size,), real_label, device=device)\n",
    "#         fake_labels = torch.full((current_batch_size,), fake_label, device=device)\n",
    "\n",
    "#         discriminator.zero_grad()\n",
    "#         outputs_real = discriminator(real_images).view(-1)\n",
    "#         loss_real = criterion(outputs_real, real_labels)\n",
    "#         loss_real.backward()\n",
    "\n",
    "#         noise = torch.randn(current_batch_size, 3, 64, 64, device=device)  \n",
    "#         fake_images = generator(noise)\n",
    "#         outputs_fake = discriminator(fake_images.detach()).view(-1)\n",
    "#         loss_fake = criterion(outputs_fake, fake_labels)\n",
    "#         loss_fake.backward()\n",
    "\n",
    "#         optimizer_D.step()\n",
    "\n",
    "\n",
    "#         generator.zero_grad()\n",
    "#         outputs_fake = discriminator(fake_images).view(-1)\n",
    "#         loss_generator = criterion(outputs_fake, real_labels) \n",
    "#         loss_generator.backward()\n",
    "\n",
    "#         optimizer_G.step()\n",
    "\n",
    "#        \n",
    "#         if i % 1 == 0:\n",
    "#             print(f\"Epoch [{epoch}/{epochs}] Batch {i}/{len(cartoon_images_loader)} \\\n",
    "#                   Loss D: {loss_real + loss_fake}, Loss G: {loss_generator}\")\n",
    "\n",
    "#    \n",
    "#     torch.save(generator.state_dict(), 'generator.pth')\n",
    "#     torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         fake_images = generator(noise).detach().cpu()\n",
    "#     img_grid = vutils.make_grid(fake_images, padding=2, normalize=True)\n",
    "#     # Convert to plt\n",
    "#     plt.imshow(img_grid.permute(1, 2, 0).squeeze())\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
